package tcc.heronsanches.ufba.fim.utils;

import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.IOException;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;
import java.text.DecimalFormat;
import java.util.Random;
import java.util.logging.Level;
import java.util.logging.Logger;
import weka.classifiers.functions.MultilayerPerceptron;
import weka.core.Instance;
import weka.core.Instances;

/**These methods was based on examples of using of MultilayerPerceptron from http://www.lac.inpe.br/~rafael.santos/Docs/TreinamentoCTI2010/JavaDMVis.pdf
and using of cross-validation from here https://weka.wikispaces.com/Generating+cross-validation+folds+(Java+approach) */
public class MultilayerPerceptronWeka {
    
    
    private static final String PATH_CLASSIFIER = "classifier.mlp";
    
    
    /**@param pathToArffFile : path where is the arrf file training*/
    public static String trainingNetwork(String pathToArffFile){
        
        ObjectOutputStream oos = null;
        String resultTesting = "";
        
        try {
            
            FileReader reader = new FileReader (pathToArffFile);
            Instances instancies = new Instances (reader);
            instancies.setClassIndex (instancies.numAttributes() - 1);
            
            //creates classifier based on Multilayer Perceptrons
            MultilayerPerceptron mlp = new MultilayerPerceptron ();
            mlp.setAutoBuild (true);
            mlp.setLearningRate (0.5);
            mlp.setMomentum (0.2);
            mlp.setTrainingTime (2000);
            mlp.setHiddenLayers ("5");
            
            int tse; //true side effect
            int tnse; //true no side effect
            int fse; //false side effect
            int fnse; //false no side effect
            int qttInstacies;
            double meanPrecision;
            double meanRecall;
            double meanAccuracy;
            int ic; //instance class generated by the classifier
            int iClass; //instance class
            
            int seed;
            int folds = 11; //TODO enhancement: passes it how a parameter
            int runs = 200; //TODO enhancement: passes it how a parameter
            
            for(int i=0; i < runs; i++){ //repeats "runs" times the stratifyed-cross-validation
            
                seed = i + 1;
                Random rand = new Random(seed);
                Instances randData = new Instances(instancies);
                randData.randomize(rand);
                randData.stratify(folds);
                
                tse = 0; 
                tnse = 0;
                fse = 0; 
                fnse = 0;
                qttInstacies = 0;
                meanPrecision = 0;
                meanRecall = 0;
                meanAccuracy = 0;
                
                for(int n=0; n < folds; n++){ //stratifyed-cross-validation
                    
                    Instances train = randData.trainCV(folds, n);
                    Instances test = randData.testCV(folds, n);
                    
                    //training network
                    mlp.buildClassifier(train);
                    
                    qttInstacies += test.numInstances();
                    Instance instanceTest;

                    for(int j =0; j < test.numInstances(); j++){ //classifying

                        
                        instanceTest = test.instance(j); //recovery the instance
                        ic = (int)mlp.classifyInstance(instanceTest); //classifies the instance
                        iClass = (int)instanceTest.classValue();

                        if (ic == iClass){ //true classification

                            if(instanceTest.classAttribute().value(iClass).contentEquals("yes")) //siddeEffect
                                tse++;
                            else
                                tnse++;

                        }else{ //false classification

                            if(instanceTest.classAttribute().value(iClass).contentEquals("yes"))
                                fse++;
                            else
                                fnse++;

                        }

                    }  
                    
                    meanAccuracy += ( (((double)tse+tnse) / (tse+tnse+fse+fnse)) / folds);
                    meanPrecision += ( ((double)tse / (tse+fse)) / folds );
                    meanRecall += ( ((double)tse / (tse+fnse)) / folds );
                    
                }
                
                DecimalFormat df = new DecimalFormat("#.####");

                /*measurements
                    precision = tp/tp+fp
                    recall = tp/tp+fn
                    accuracy = tp+tn/tp+tn+fp+fn
                */
                    
                resultTesting += "number of instancies: "+qttInstacies+"\n"
                            + "true side effect: "+tse+"\n"
                            + "true no side effect: "+tnse+"\n"
                            + "false side effect: "+fse+"\n"
                            + "false no side effect: "+fnse+"\n\n"
                            + "precision: "+df.format( meanPrecision * 100)+"%\n"
                            + "recall: "+df.format(meanRecall * 100)+"%\n"
                            + "accuracy: "+df.format( meanAccuracy * 100)+"%\n"
                            + "***************************************************************************************\n\n";
                
            }

            //saves classifier to use in other moment
            oos = new ObjectOutputStream (new FileOutputStream(MultilayerPerceptronWeka.PATH_CLASSIFIER));
            oos.writeObject(mlp);
            oos.close();
                        
        } catch (IOException ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } catch (Exception ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } finally {
            try {
                oos.close();
            } catch (IOException ex) {
                Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
            }
        }
        
        return resultTesting;
        
    }
    
    
    /**@param pathToArffFile : path where is the arrf file training*/
    public static String trainingNetworkHoldout(String pathToArffFile){
        
        ObjectOutputStream oos = null;
        String resultTesting = "";
        String resultInd = "";
        DecimalFormat df = new DecimalFormat("#.####");
        
        try {
            
            FileReader reader = new FileReader (pathToArffFile);
            Instances instancies = new Instances (reader);
            instancies.setClassIndex (instancies.numAttributes() - 1);
            
            //creates classifier based on Multilayer Perceptrons
            MultilayerPerceptron mlp = new MultilayerPerceptron ();
            mlp.setAutoBuild (true);
            mlp.setLearningRate (0.5);
            mlp.setMomentum (0.2);
            mlp.setTrainingTime (2000);
            mlp.setHiddenLayers ("5");
            
            /** total */
            int tse = 0; //true side effect
            int tnse = 0; //true no side effect
            int fse = 0; //false side effect
            int fnse = 0; //false no side effect
            int qttInstacies = 0;
            
            double meanPrecision = 0;
            double meanRecall = 0;
            double meanAccuracy = 0;
            
            /** individual **/
            int tseInd; //true side effect
            int tnseInd; //true no side effect
            int fseInd; //false side effect
            int fnseInd; //false no side effect

            int ic; //instance class generated by the classifier
            int iClass; //instance class
            
            int seed;
            int trainSize;
            int testSize;
            int runs = 10000; //TODO enhancement: passes it how a parameter
            double percentToTrain = 0.16; //TODO enhancement: passes it how a parameter integer and make the necessary modification on calc
                        
            for(int i=0; i < runs; i++){ //repeats "runs" times the holdout-randomized
            
                seed = i + 1;
                Random rand = new Random(seed);
                Instances randData = new Instances(instancies);
                randData.randomize(rand);
                
                //split train and test
                trainSize = (int) Math.round(randData.numInstances() * percentToTrain);
                testSize = randData.numInstances() - trainSize;
                Instances train = new Instances(randData, 0, trainSize);
                Instances test = new Instances(randData, trainSize, testSize);
                
                tseInd = 0; 
                tnseInd = 0;
                fseInd = 0; 
                fnseInd = 0;

                //training network
                mlp.buildClassifier(train);

                qttInstacies += test.numInstances();
                Instance instanceTest;

                for(int j =0; j < test.numInstances(); j++){ //classifying

                    instanceTest = test.instance(j); //recovery the instance
                    ic = (int)mlp.classifyInstance(instanceTest); //classifies the instance
                    iClass = (int)instanceTest.classValue();

                    if (ic == iClass){ //true classification

                        if(instanceTest.classAttribute().value(iClass).contentEquals("yes")){ //siddeEffect
                            
                            tse++;
                            tseInd++;
                            
                        }else{
                            
                            tnse++;
                            tnseInd++;
                            
                        }
                        
                    }else{ //false classification

                        if(instanceTest.classAttribute().value(iClass).contentEquals("yes")){
                            
                            fse++;
                            fseInd++;
                            
                        }else{
                            
                            fnse++;
                            fnseInd++;
                            
                        }
                        
                    }

                }  

                meanAccuracy += ( (((double)tse+tnse) / (tse+tnse+fse+fnse)) / runs);
                meanPrecision += ( ((double)tse / (tse+fse)) / runs );
                meanRecall += ( ((double)tse / (tse+fnse)) / runs );
                    
                /*measurements
                    precision = tp/tp+fp
                    recall = tp/tp+fn
                    accuracy = tp+tn/tp+tn+fp+fn
                */
                    
                resultInd += "number of instancies: "+test.numInstances()+"\n"
                            + "true side effect: "+tseInd+"\n"
                            + "true no side effect: "+tnseInd+"\n"
                            + "false side effect: "+fseInd+"\n"
                            + "false no side effect: "+fnseInd+"\n\n"
                            + "precision: "+df.format( ((double)tse / (tse+fse)) * 100)+"%\n"
                            + "recall: "+df.format( ((double)tse / (tse+fnse)) * 100)+"%\n"
                            + "accuracy: "+df.format( (((double)tse+tnse) / (tse+tnse+fse+fnse)) * 100)+"%\n"
                            + "***************************************************************************************\n\n";
                
            }
            
            resultTesting += "TOTAL RESULT\n\n"
                            + "number of instancies: "+qttInstacies+"\n"
                            + "true side effect: "+tse+"\n"
                            + "true no side effect: "+tnse+"\n"
                            + "false side effect: "+fse+"\n"
                            + "false no side effect: "+fnse+"\n\n"
                            + "mean precision: "+df.format( meanPrecision * 100)+"%\n"
                            + "mean recall: "+df.format(meanRecall * 100)+"%\n"
                            + "mean accuracy: "+df.format( meanAccuracy * 100)+"%\n"
                            + "\n\n"
                    + "INDIVIDUAL RESULTS\n\n"+resultInd;

            //saves classifier to use in other moment
            oos = new ObjectOutputStream (new FileOutputStream(MultilayerPerceptronWeka.PATH_CLASSIFIER));
            oos.writeObject(mlp);
            oos.close();
                        
        } catch (IOException ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } catch (Exception ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } finally {
            try {
                oos.close();
            } catch (IOException ex) {
                Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
            }
        }
        
        return resultTesting;
        
    }
    
    
    /**@param pathToArffFile : path where is the arrf file testing*/
    public static String testingNetwork(String pathToArffFile) throws Exception{
        
       ObjectInputStream ois = null;
       String resultTesting = "";
       
        try {
            
            ois = new ObjectInputStream (new FileInputStream(MultilayerPerceptronWeka.PATH_CLASSIFIER));
            
            //ois = new ObjectInputStream (new FileInputStream("/home/heron/Documents/ufba/pf/maquete/experimento/treinamento/dados/dataset/resultado_final/modelCrossValidation.mlp.model"));
            MultilayerPerceptron mlp2 = (MultilayerPerceptron) ois.readObject();
            ois.close ();
            
            FileReader reader2 = new FileReader (pathToArffFile);
            Instances instancies2 = new Instances(reader2);
            instancies2.setClassIndex(instancies2.numAttributes() - 1);
            
            int tse = 0; //true side effect
            int tnse = 0; //true no side effect
            int fse = 0; //false side effect
            int fnse = 0; //false no side effect
            
            int qttInstacies = instancies2.numInstances();
            Instance instance2;
            int ic; //instance class
            
            //classifying
            for (int i =0; i < instancies2.numInstances(); i++){
                
                // Recuperamos cada uma das instâncias.
                instance2 = instancies2.instance(i);
                
                // Classificamos esta instância.
                ic = (int)mlp2.classifyInstance(instance2);
                
                if (ic == (int)instance2.classValue()){ //true classification
                    
                    if((int)instance2.classValue() == 1) //siddeEffect
                        tse++;
                    else
                        tnse++;
                    
                }else{ //false classification
                    
                    if((int)instance2.classValue() == 1)
                        fse++;
                    else
                        fnse++;
                    
                }
                
            }   
            
            DecimalFormat df = new DecimalFormat("#.####");
            
            /*measurements
                precision = tp/tp+fp
                recall = tp/tp+fn
                accuracy = tp+tn/tp+tn+fp+fn
            */
                
            resultTesting += "number of instancies: "+qttInstacies+"\n"
                    + "true side effect: "+tse+"\n"
                    + "true no side effect: "+tnse+"\n"
                    + "false side effect: "+fse+"\n"
                    + "false no side effect: "+fnse+"\n\n"
                    + "precision: "+df.format( ((double)tse / (tse+fse)) * 100)+"%\n"
                    + "recall: "+df.format(((double)tse / (tse+fnse)) * 100)+"%\n"
                    + "accuracy: "+df.format( (((double)tse+tnse) / (tse+tnse+fse+fnse)) * 100)+"%\n";
            
        } catch (IOException ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } catch (ClassNotFoundException ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } finally {
            try {
                ois.close();
            } catch (IOException ex) {
                Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
            }
        }
        
        return resultTesting;
        
    }
    
    
    /**@param pathToArffFile : path where is the arrf file testing*/
    public static boolean isSideEffect(String pathToArffFile){ 
                
        try {
        
            ObjectInputStream ois = null;
            ois = new ObjectInputStream (new FileInputStream(MultilayerPerceptronWeka.PATH_CLASSIFIER));
            MultilayerPerceptron mlp = (MultilayerPerceptron) ois.readObject();
            ois.close ();

            Instances instancies = new Instances(new FileReader (pathToArffFile));
            instancies.setClassIndex(instancies.numAttributes() -1);

            int isSideEffect_ = (int)mlp.classifyInstance(instancies.instance(0));
            
            if(isSideEffect_ == 1)
                return true;
            
        } catch (IOException ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } catch (ClassNotFoundException ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        } catch (Exception ex) {
            Logger.getLogger(MultilayerPerceptronWeka.class.getName()).log(Level.SEVERE, null, ex);
        }
        
        return false;
        
    }

    
}